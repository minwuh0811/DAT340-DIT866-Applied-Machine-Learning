{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Working with a dataset with categorical features\n",
    "In Assignment 1A, we didn't have to do much preprocessing, because all the features in the two datasets were numerical. (Actually, in the second dataset, we removed all non-numerical features.) In this assignment, we'll instead consider how to deal with non-numerical features.\n",
    "\n",
    "We'll use the famous Adult dataset. This is a binary classification task, where our task is to predict whether an American individual earns more than $50,000 a year, given a number of numerical and categorical features. (The dataset was extracted from a 1994 census database.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Reading the data \n",
    "Please download the two CSV files, the training set and the test set, and save them into your working directory This is the official train/test split defined by the people who created the dataset. It's the same data as in the the public distribution, except that we converted the format into a standard CSV format. \n",
    "Write code to read the CSV file, for instance by using Pandas as in Assignment 1A. Then split the data into an input part X and an output part Y. The output variable, which the classifier will predict, is called target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "  \n",
    "# Read the CSV file.\n",
    "data_train = pd.read_csv('adult_train.csv')\n",
    "data_test = pd.read_csv('adult_test.csv')\n",
    "data_train_shuffled = data_train.sample(frac=1.0, random_state=0)\n",
    "data_test_shuffled = data_test.sample(frac=1.0, random_state=0)\n",
    "X_train = data_train_shuffled.drop('target', axis=1)\n",
    "Y_train=data_train_shuffled['target'].dropna()\n",
    "X_test = data_test_shuffled.drop('target', axis=1)\n",
    "Y_test=data_test_shuffled['target'].dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Encoding the features as numbers. \n",
    "If you look at the data, you will note that it contains several features with categorical values, such as workclass, education etc. All scikit-learn models work with numerical data internally; this means that the categorical features need to be converted to numbers. The most straightforward way to carry out such a conversion is to use one-hot encoding of the features, also known as dummy variables in statistics. In this approach, we define one new column for each observed value of the feature. \n",
    "Scikit-learn includes a number of tools that can do one-hot encoding of categorical features and we'll see how to use one of them, the DictVectorizer. An alternative approach that is a bit more Pandas-friendly and gives more low-level control is to use the recently introduced ColumnTransformer; if you're interested, you can read an introduction to this approach here. We won't use a ColumnTransformer here because it will make Task 3 in this assignment a bit too annoying to solve. \n",
    "The DictVectorizer is used when we store our features as named attributes in dictionaries. For instance, we could represent one individual from the Adult dataset as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "X_train_dicts = X_train.to_dict('records')\n",
    "X_test_dicts=X_test.to_dict('records')\n",
    "dv = DictVectorizer()\n",
    "X_train_encoded = dv.fit_transform(X_train_dicts)\n",
    "X_test_encoded = dv.transform(X_test_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Combining the steps. \n",
    "In the example above, we first transformed the list of dictionaries into a numerical matrix, and then we used this matrix when training the classifier. A separate preprocessing step was carried out for the test set. \n",
    "In machine learning setups, we often use long chains of preprocessing steps. The one-hot encoding is one example, and other such steps might be scaling, feature selection, imputation of missing values, etc. As you can imagine, keeping track of the preprocessing steps can be tedious and error-prone, so it makes sense to handle such preprocessing chains automatically. \n",
    "A Pipeline consists of a sequence of scikit-learn modules. The most convenient way to build a Pipeline is to use the utility function make_pipeline. For instance, to build a pipeline consisting of a vectorization step and then a decision tree classifier.\n",
    "The Pipeline can be treated as any classifier: we can call fit and predict as usual. Concretely, when we call fit on a Pipeline, it will in turn call fit_transform on all intermediate steps and then fit on the final step. When we call predict, transform will be called on the intermediate steps and then predict on the final step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8163754941449552"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "  DictVectorizer(),\n",
    "  DecisionTreeClassifier()\n",
    ")\n",
    "\n",
    "pip=pipeline.fit(X_train_dicts,Y_train)\n",
    "cross_val_score(pip, X_train_dicts,Y_train, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is built including GradientBoostingClassifier together with DictVectorizer to do  one-hot encoding of categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Decision trees and random forests\n",
    "In the previous assignment, in one of the optional tasks (Task 4, step 4) we investigated the performance of a regression model as a function of the depth of the decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underfitting and overfitting in decision tree classifiers. \n",
    "As the first step, please reproduce this experiment for this dataset, but now using scikit-learn's DecisionTreeClassifier instead of your own regression model. Of course, you should use an evaluation metric for classification, not the mean squared error. Do you see a similar effect now? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1387d856128>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "score_test=[]\n",
    "score=[]\n",
    "N=[]\n",
    "for i in range(1,15):\n",
    "    pipeline = make_pipeline(\n",
    "      DictVectorizer(),\n",
    "      DecisionTreeClassifier(max_depth=i)\n",
    "    )\n",
    "    pip=pipeline.fit(X_train_dicts,Y_train)\n",
    "    Y_guess = pip.predict(X_test_dicts)\n",
    "    score.append(cross_val_score(pip, X_train_dicts,Y_train, cv=5, scoring='accuracy').mean())\n",
    "    score_test.append(accuracy_score(Y_test, Y_guess))\n",
    "    N.append(i)\n",
    "plt.plot(N,score_test,color='purple',marker='o', markerfacecolor='purple', markersize=4, linewidth=2)\n",
    "plt.plot(N,score,color='green',marker='o', markerfacecolor='green', markersize=4, linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underfitting and overfitting in random forest classifiers. \n",
    "Replace the DecisionTreeClassifier with a RandomForestClassifier. \n",
    "The hyperparameter n_estimators defines the number of decision trees used in ensemble. \n",
    "Investigate how the underfitting/overfitting curve is affected by the number of trees. You can investigate ensemble sizes ranging from 1 up until a few hundred. \n",
    "Hint. These experiments can take some time to run. When n_estimators is large, you can reduce the training time quite a bit by adjusting the hyperparameter n_jobs, which will train several trees in parallel. By default, only one CPU core is used, but if you set n_jobs=-1, all cores will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "score_test=[]\n",
    "score=[]\n",
    "N=[]\n",
    "for i in range(1,501,50):\n",
    "    pipeline = make_pipeline(\n",
    "      DictVectorizer(),\n",
    "      RandomForestClassifier(n_estimators=i, n_jobs=-1)\n",
    "    )\n",
    "    pip=pipeline.fit(X_train_dicts,Y_train)\n",
    "    Y_guess = pip.predict(X_test_dicts)\n",
    "    score.append(cross_val_score(pip, X_train_dicts,Y_train, cv=5, scoring='accuracy').mean())\n",
    "    score_test.append(accuracy_score(Y_test, Y_guess))\n",
    "    N.append(i)\n",
    "plt.plot(N,score_test,color='purple',marker='o', markerfacecolor='purple', markersize=4, linewidth=2)\n",
    "plt.plot(N,score,color='green',marker='o', markerfacecolor='green', markersize=4, linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things that you might want to discuss in your report: \n",
    "What's the difference between the curve for a decision tree and for a random forest with an ensemble size of 1, and why do we see this difference? \n",
    "What happens with the curve for random forests as the ensemble size grows? \n",
    "What happens with the best observed test set accuracy as the ensemble size grows? \n",
    "What happens with the training time as the ensemble size grows? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Feature importances in random forest classifiers\n",
    "Decision trees and random forests are trained by computing importance scores for individual features in different ways: information gain, Gini impurity, variance reduction, etc. \n",
    "As a way to make our classifiers more interpretable, we can print the importance scores. In scikit-learn, decision trees and ensemble classifiers such as random forests all define an attribute called feature_importances_ (note the final underscore in this name). This is a NumPy array that stores the importance scores for each feature column in the training data matrix. For random forests and other tree ensembles, these importance scores are computed by averaging the scores when training all the different trees in the ensemble. \n",
    "To make these importance scores easier to understand, we can use the attribute feature_names_ (note the underscore again) in the DictVectorizer. \n",
    "Sort the features by importance scores in reverse order (so that the most important feature comes first), inspect the first few of these features, and try to reason about why you got this result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
