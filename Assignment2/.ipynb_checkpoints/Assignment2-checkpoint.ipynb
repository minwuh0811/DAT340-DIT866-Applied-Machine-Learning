{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"a2a_train_final.tsv\", sep=\"\\t\") \n",
    "#data = pd.read_csv(\"a2a_train_round1.tsv\", sep=\"\\t\") \n",
    "data.columns = [\"Class\", \"Comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the actual classification algorithm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# for converting training and test datasets into matrices\n",
    "# TfidfVectorizer does this specifically for documents\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# for bundling the vectorizer and the classifier as a single \"package\"\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# for splitting the dataset into training and test sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the quality of the classifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0/0</td>\n",
       "      <td>Being a member of the European Union is a bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0/0</td>\n",
       "      <td>Brexit is bad. Immigrants make Britain great. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0/0</td>\n",
       "      <td>Britain is basically Pompeii if the Pompeii ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1</td>\n",
       "      <td>Britain's exit is a huge blow to the dream of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/-1</td>\n",
       "      <td>Bye, Bye EU, Bye, Bye...Fireworks are going of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13511</th>\n",
       "      <td>1/1</td>\n",
       "      <td>”Fake news! UK will prosper as soon as Bojo si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13512</th>\n",
       "      <td>0/1</td>\n",
       "      <td>† I know exactly how it will end. †</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13513</th>\n",
       "      <td>1/1</td>\n",
       "      <td>🇬🇧 Hard Brexit all the way 🇬🇧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514</th>\n",
       "      <td>0/0</td>\n",
       "      <td>😆 it's funny, when the brits sees the raise in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>0/0</td>\n",
       "      <td>🤣🤣 imagine that bulgarian and romanian passpor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13516 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class                                            Comment\n",
       "0       0/0  Being a member of the European Union is a bit ...\n",
       "1       0/0  Brexit is bad. Immigrants make Britain great. ...\n",
       "2       0/0  Britain is basically Pompeii if the Pompeii ha...\n",
       "3       1/1  Britain's exit is a huge blow to the dream of ...\n",
       "4      1/-1  Bye, Bye EU, Bye, Bye...Fireworks are going of...\n",
       "...     ...                                                ...\n",
       "13511   1/1  ”Fake news! UK will prosper as soon as Bojo si...\n",
       "13512   0/1                † I know exactly how it will end. †\n",
       "13513   1/1                      🇬🇧 Hard Brexit all the way 🇬🇧\n",
       "13514   0/0  😆 it's funny, when the brits sees the raise in...\n",
       "13515   0/0  🤣🤣 imagine that bulgarian and romanian passpor...\n",
       "\n",
       "[13516 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33781"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "test = Counter(\" \".join(data[\"Comment\"]).split())\n",
    "len(test.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Text data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Drop inconsistent annotation \n",
    "\n",
    "Drop those comments with inconsistent annotation. 81.6% comments are filtered out after this step, containing 50.4% pro-brexit(1) and 49.6% anti-brexit(0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0/0</td>\n",
       "      <td>Being a member of the European Union is a bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0/0</td>\n",
       "      <td>Brexit is bad. Immigrants make Britain great. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0/0</td>\n",
       "      <td>Britain is basically Pompeii if the Pompeii ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1</td>\n",
       "      <td>Britain's exit is a huge blow to the dream of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/1</td>\n",
       "      <td>Death to the EU, Death to the EU!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13510</th>\n",
       "      <td>1/1</td>\n",
       "      <td>“we have made our choice”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13511</th>\n",
       "      <td>1/1</td>\n",
       "      <td>”Fake news! UK will prosper as soon as Bojo si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13513</th>\n",
       "      <td>1/1</td>\n",
       "      <td>🇬🇧 Hard Brexit all the way 🇬🇧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514</th>\n",
       "      <td>0/0</td>\n",
       "      <td>😆 it's funny, when the brits sees the raise in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>0/0</td>\n",
       "      <td>🤣🤣 imagine that bulgarian and romanian passpor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class                                            Comment\n",
       "0       0/0  Being a member of the European Union is a bit ...\n",
       "1       0/0  Brexit is bad. Immigrants make Britain great. ...\n",
       "2       0/0  Britain is basically Pompeii if the Pompeii ha...\n",
       "3       1/1  Britain's exit is a huge blow to the dream of ...\n",
       "6       1/1                  Death to the EU, Death to the EU!\n",
       "...     ...                                                ...\n",
       "13510   1/1                          “we have made our choice”\n",
       "13511   1/1  ”Fake news! UK will prosper as soon as Bojo si...\n",
       "13513   1/1                      🇬🇧 Hard Brexit all the way 🇬🇧\n",
       "13514   0/0  😆 it's funny, when the brits sees the raise in...\n",
       "13515   0/0  🤣🤣 imagine that bulgarian and romanian passpor...\n",
       "\n",
       "[11004 rows x 2 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def find_majority(k):\n",
    "#    myMap = {}\n",
    "#    maximum = ( '', 0 ) # (occurring element, occurrences)\n",
    "#    for n in k:\n",
    "#        if n in myMap: myMap[n] += 1\n",
    "#        else: myMap[n] = 1\n",
    "#\n",
    "#        # Keep track of maximum on the go\n",
    "#        if myMap[n] > maximum[1]: maximum = (n,myMap[n])\n",
    "#\n",
    "#    return maximum\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    arr = row[\"Class\"].split(\"/\")\n",
    "    if(len(set(arr)) > 1):\n",
    "        #print(arr)\n",
    "        data = data.drop(index, axis=0)\n",
    "    #else:\n",
    "        #data.loc[index][\"Class\"]=arr[0]\n",
    "#data.reset_index()\n",
    "\n",
    "#for index, row in data.iterrows():\n",
    "#    arr = row[\"Class\"].split(\"/\")\n",
    "#    #if(len(set(arr)) > 1):\n",
    "#    if(arr.count('1') > arr.count('0')):\n",
    "#        #print(arr)\n",
    "#        data.set_value(index, \"Class\", 1)\n",
    "#    elif(arr.count('0') > arr.count('1')):\n",
    "#        data.set_value(index, \"Class\", 0)\n",
    "#    else:\n",
    "#        data.set_value(index, \"Class\", 1)\n",
    "#        #data = data.drop(index, axis=0)\n",
    "#data = data.reset_index()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pro-brexit = 0.4969 and anti-brexit=0.5031\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt=Counter(data[\"Class\"])\n",
    "print(\"pro-brexit = %0.4f and anti-brexit=%0.4f\" %(cnt['0']/(cnt['0']+cnt['1']), cnt['1']/(cnt['0']+cnt['1'])))\n",
    "\n",
    "\n",
    "#test = Counter(\" \".join(data[data[\"Class\"] == '1'][\"Comment\"]).split()).most_common()[:-1000-1:-1]\n",
    "#test2 = Counter(\" \".join(data[data[\"Class\"] == '0'][\"Comment\"]).split()).most_common()[:-1000-1:-1]\n",
    "#test = Counter(\" \".join(data[\"Comment\"]).split()).most_common()[:-1000-1:-1]\n",
    "test = Counter(\" \".join(data[\"Comment\"]).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29687"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0/0</td>\n",
       "      <td>being a member of the european union is a bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0/0</td>\n",
       "      <td>brexit is bad. immigrants make britain great. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0/0</td>\n",
       "      <td>britain is basically pompeii if the pompeii ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1</td>\n",
       "      <td>britain's exit is a huge blow to the dream of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/1</td>\n",
       "      <td>death to the eu, death to the eu!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13510</th>\n",
       "      <td>1/1</td>\n",
       "      <td>“we have made our choice”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13511</th>\n",
       "      <td>1/1</td>\n",
       "      <td>”fake news! uk will prosper as soon as bojo si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13513</th>\n",
       "      <td>1/1</td>\n",
       "      <td>🇬🇧 hard brexit all the way 🇬🇧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514</th>\n",
       "      <td>0/0</td>\n",
       "      <td>😆 it's funny, when the brits sees the raise in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>0/0</td>\n",
       "      <td>🤣🤣 imagine that bulgarian and romanian passpor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class                                            Comment\n",
       "0       0/0  being a member of the european union is a bit ...\n",
       "1       0/0  brexit is bad. immigrants make britain great. ...\n",
       "2       0/0  britain is basically pompeii if the pompeii ha...\n",
       "3       1/1  britain's exit is a huge blow to the dream of ...\n",
       "6       1/1                  death to the eu, death to the eu!\n",
       "...     ...                                                ...\n",
       "13510   1/1                          “we have made our choice”\n",
       "13511   1/1  ”fake news! uk will prosper as soon as bojo si...\n",
       "13513   1/1                      🇬🇧 hard brexit all the way 🇬🇧\n",
       "13514   0/0  😆 it's funny, when the brits sees the raise in...\n",
       "13515   0/0  🤣🤣 imagine that bulgarian and romanian passpor...\n",
       "\n",
       "[11004 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Comment']=data['Comment'].str.lower()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26031"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Counter(\" \".join(data[\"Comment\"]).split())\n",
    "len(test.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Tokenization\n",
    "\n",
    "Tokenization is a step which splits longer strings of text into smaller pieces, or tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0/0</td>\n",
       "      <td>being a member of the european union is a bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0/0</td>\n",
       "      <td>brexit is bad . immigrants make britain great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0/0</td>\n",
       "      <td>britain is basically pompeii if the pompeii ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1</td>\n",
       "      <td>britain 's exit is a huge blow to the dream of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/1</td>\n",
       "      <td>death to the eu , death to the eu !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13510</th>\n",
       "      <td>1/1</td>\n",
       "      <td>“ we have made our choice ”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13511</th>\n",
       "      <td>1/1</td>\n",
       "      <td>” fake news ! uk will prosper as soon as bojo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13513</th>\n",
       "      <td>1/1</td>\n",
       "      <td>🇬🇧 hard brexit all the way 🇬🇧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514</th>\n",
       "      <td>0/0</td>\n",
       "      <td>😆 it 's funny , when the brits sees the raise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>0/0</td>\n",
       "      <td>🤣🤣 imagine that bulgarian and romanian passpor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class                                            Comment\n",
       "0       0/0  being a member of the european union is a bit ...\n",
       "1       0/0  brexit is bad . immigrants make britain great ...\n",
       "2       0/0  britain is basically pompeii if the pompeii ha...\n",
       "3       1/1  britain 's exit is a huge blow to the dream of...\n",
       "6       1/1                death to the eu , death to the eu !\n",
       "...     ...                                                ...\n",
       "13510   1/1                        “ we have made our choice ”\n",
       "13511   1/1  ” fake news ! uk will prosper as soon as bojo ...\n",
       "13513   1/1                      🇬🇧 hard brexit all the way 🇬🇧\n",
       "13514   0/0  😆 it 's funny , when the brits sees the raise ...\n",
       "13515   0/0  🤣🤣 imagine that bulgarian and romanian passpor...\n",
       "\n",
       "[11004 rows x 2 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, string, unicodedata\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "       data.loc[index]['Comment'] = \" \".join(nltk.word_tokenize(data['Comment'][index]))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16071"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Counter(\" \".join(data[\"Comment\"]).split())\n",
    "len(test.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0/0</td>\n",
       "      <td>being a member of the european union is a bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0/0</td>\n",
       "      <td>brexit is bad immigrants make britain great th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0/0</td>\n",
       "      <td>britain is basically pompeii if the pompeii ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1</td>\n",
       "      <td>britain s exit is a huge blow to the dream of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/1</td>\n",
       "      <td>death to the eu death to the eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13510</th>\n",
       "      <td>1/1</td>\n",
       "      <td>we have made our choice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13511</th>\n",
       "      <td>1/1</td>\n",
       "      <td>fake news uk will prosper as soon as bojo sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13513</th>\n",
       "      <td>1/1</td>\n",
       "      <td>hard brexit all the way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514</th>\n",
       "      <td>0/0</td>\n",
       "      <td>it s funny when the brits sees the raise in ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>0/0</td>\n",
       "      <td>imagine that bulgarian and romanian passport w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class                                            Comment\n",
       "0       0/0  being a member of the european union is a bit ...\n",
       "1       0/0  brexit is bad immigrants make britain great th...\n",
       "2       0/0  britain is basically pompeii if the pompeii ha...\n",
       "3       1/1  britain s exit is a huge blow to the dream of ...\n",
       "6       1/1                    death to the eu death to the eu\n",
       "...     ...                                                ...\n",
       "13510   1/1                            we have made our choice\n",
       "13511   1/1  fake news uk will prosper as soon as bojo sign...\n",
       "13513   1/1                            hard brexit all the way\n",
       "13514   0/0  it s funny when the brits sees the raise in ta...\n",
       "13515   0/0  imagine that bulgarian and romanian passport w...\n",
       "\n",
       "[11004 rows x 2 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "#print(index)\n",
    "#data['Comment'][13514].split()\n",
    "#\" \".join(remove_punctuation(data['Comment'][13514].split()))\n",
    "for index, row in data.iterrows():\n",
    "    data.loc[index]['Comment'] = \" \".join(remove_punctuation(data['Comment'][index].split()))\n",
    "data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15105"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Counter(\" \".join(data[\"Comment\"]).split())\n",
    "len(test.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 replace_numbers\n",
    "Replace all interger occurrences in list of tokenized words with textual representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0/0</td>\n",
       "      <td>being a member of the european union is a bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0/0</td>\n",
       "      <td>brexit is bad immigrants make britain great th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0/0</td>\n",
       "      <td>britain is basically pompeii if the pompeii ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1</td>\n",
       "      <td>britain s exit is a huge blow to the dream of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/1</td>\n",
       "      <td>death to the eu death to the eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13510</th>\n",
       "      <td>1/1</td>\n",
       "      <td>we have made our choice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13511</th>\n",
       "      <td>1/1</td>\n",
       "      <td>fake news uk will prosper as soon as bojo sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13513</th>\n",
       "      <td>1/1</td>\n",
       "      <td>hard brexit all the way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514</th>\n",
       "      <td>0/0</td>\n",
       "      <td>it s funny when the brits sees the raise in ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>0/0</td>\n",
       "      <td>imagine that bulgarian and romanian passport w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class                                            Comment\n",
       "0       0/0  being a member of the european union is a bit ...\n",
       "1       0/0  brexit is bad immigrants make britain great th...\n",
       "2       0/0  britain is basically pompeii if the pompeii ha...\n",
       "3       1/1  britain s exit is a huge blow to the dream of ...\n",
       "6       1/1                    death to the eu death to the eu\n",
       "...     ...                                                ...\n",
       "13510   1/1                            we have made our choice\n",
       "13511   1/1  fake news uk will prosper as soon as bojo sign...\n",
       "13513   1/1                            hard brexit all the way\n",
       "13514   0/0  it s funny when the brits sees the raise in ta...\n",
       "13515   0/0  imagine that bulgarian and romanian passport w...\n",
       "\n",
       "[11004 rows x 2 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inflect\n",
    "def replace_numbers(words):\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    data.loc[index]['Comment'] = \" \".join(replace_numbers(data['Comment'][index].split()))\n",
    "data  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14905"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Counter(\" \".join(data[\"Comment\"]).split())\n",
    "len(test.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6 remove_non_ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0/0</td>\n",
       "      <td>being a member of the european union is a bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0/0</td>\n",
       "      <td>brexit is bad immigrants make britain great th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0/0</td>\n",
       "      <td>britain is basically pompeii if the pompeii ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1</td>\n",
       "      <td>britain s exit is a huge blow to the dream of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/1</td>\n",
       "      <td>death to the eu death to the eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13510</th>\n",
       "      <td>1/1</td>\n",
       "      <td>we have made our choice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13511</th>\n",
       "      <td>1/1</td>\n",
       "      <td>fake news uk will prosper as soon as bojo sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13513</th>\n",
       "      <td>1/1</td>\n",
       "      <td>hard brexit all the way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514</th>\n",
       "      <td>0/0</td>\n",
       "      <td>it s funny when the brits sees the raise in ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>0/0</td>\n",
       "      <td>imagine that bulgarian and romanian passport w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class                                            Comment\n",
       "0       0/0  being a member of the european union is a bit ...\n",
       "1       0/0  brexit is bad immigrants make britain great th...\n",
       "2       0/0  britain is basically pompeii if the pompeii ha...\n",
       "3       1/1  britain s exit is a huge blow to the dream of ...\n",
       "6       1/1                    death to the eu death to the eu\n",
       "...     ...                                                ...\n",
       "13510   1/1                            we have made our choice\n",
       "13511   1/1  fake news uk will prosper as soon as bojo sign...\n",
       "13513   1/1                            hard brexit all the way\n",
       "13514   0/0  it s funny when the brits sees the raise in ta...\n",
       "13515   0/0  imagine that bulgarian and romanian passport w...\n",
       "\n",
       "[11004 rows x 2 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "for index, row in data.iterrows():\n",
    "    data.loc[index]['Comment'] = \" \".join(remove_non_ascii(data['Comment'][index].split()))\n",
    "data  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14897"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Counter(\" \".join(data[\"Comment\"]).split())\n",
    "len(test.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.7 Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0/0</td>\n",
       "      <td>member european union bit like going sandwich ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0/0</td>\n",
       "      <td>brexit bad immigrants make britain great also ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0/0</td>\n",
       "      <td>britain basically pompeii pompeii voted volcan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1</td>\n",
       "      <td>britain exit huge blow dream united europe end...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/1</td>\n",
       "      <td>death eu death eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13510</th>\n",
       "      <td>1/1</td>\n",
       "      <td>made choice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13511</th>\n",
       "      <td>1/1</td>\n",
       "      <td>fake news uk prosper soon bojo signes fantasti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13513</th>\n",
       "      <td>1/1</td>\n",
       "      <td>hard brexit way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514</th>\n",
       "      <td>0/0</td>\n",
       "      <td>funny brits sees raise taxes commercial negoti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>0/0</td>\n",
       "      <td>imagine bulgarian romanian passport better bri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class                                            Comment\n",
       "0       0/0  member european union bit like going sandwich ...\n",
       "1       0/0  brexit bad immigrants make britain great also ...\n",
       "2       0/0  britain basically pompeii pompeii voted volcan...\n",
       "3       1/1  britain exit huge blow dream united europe end...\n",
       "6       1/1                                  death eu death eu\n",
       "...     ...                                                ...\n",
       "13510   1/1                                        made choice\n",
       "13511   1/1  fake news uk prosper soon bojo signes fantasti...\n",
       "13513   1/1                                    hard brexit way\n",
       "13514   0/0  funny brits sees raise taxes commercial negoti...\n",
       "13515   0/0  imagine bulgarian romanian passport better bri...\n",
       "\n",
       "[11004 rows x 2 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    data.loc[index]['Comment'] = \" \".join(remove_stopwords(data['Comment'][index].split()))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14749"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Counter(\" \".join(data[\"Comment\"]).split())\n",
    "len(test.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.8 Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    data.loc[index]['Comment'] = \" \".join(replace_numbers(data['Comment'][index].split()))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['being', 'a', 'member', 'of', 'the', 'european', 'union', 'is', 'bit', 'like', 'going', 'to', 'and', 'three', 'with', 'five', 'getting', 'back', 'over', 'one', 'thousand', 'in', 'change', 'brexit', 'bad', 'immigrants', 'make', 'britain', 'great', 'they', 'also', 'your', 'food', 'london', 'anti', 'on', 'bill', 'basically', 'if', 'had', 'voted', 'for', 'i', 'm', 'dead', 's', 'exit', 'huge', 'blow', 'dream', 'united', 'europe', 'no', 'it', 'end', 'an', 'globalist', 'system', 'eu', 'its', 'power', 'death', 'lost', 'more', 'now', 'has', 'decided', 're', 'happy', 'leave', 'as', 'long', 'can', 'keep', 'our', 'cash', 'use', 'us', 'military', 'willing', 'hand', 'down', 'rules', 'forever', 'by', 'any', 'form', 'british', 'was', 'major', 'still', 'world', 'what', 'me', 'march', 'two', 'nineteen', 'set', 'deal', 'worked', 'does', 'not', 'serve', 'but', 'brussels', 'ca', 'nt', 'begin', 'we', 'public', 'are', 'upon', 'politicians', 'at', 'next', 'general', 'election', 'sell', 'short', 'will', 'be', 'parties', 'thirty', 'years', 'while', 'red', 'blue', 'who', 'played', 'their', 'part', 'this', 'utterly', 'traitors', 'may', 'cut', 'get', 'right', 'hold', 'you', 'account', 'do', 'watching', 'after', 'forty-seven', 'membership', 'fake', 'news', 'started', 'thousand,', 'nine', 'hundred', 'or', 'big', 'lie', 'all', 'along', 'nations', 'should', 'towards', 'superstate', 'without', 'people', 'happening', 'each', 'having', 'economic', 'purpose', 'which', 'eventually', 'lead', 'how', 'thats', 'that', 'haha', 'think', 'seen', 'greater', 'political', 'integration', 'france', 'germany', 'then', 'uk', 'have', 'confidence', 'future', 'however', 'went', 'way', 'members', 'failing', 'reform', 'suffering', 'financial', 'truth', 'english', 'tough', 'every', 'day', 'please', 'ask', 'help', 'don', 't', 'decisions', 'my', 'hands', 'terrible', 'name', 'sounds', 'eat', 'when', 'know', 'fucking', 'mistake', 'wants', 'so', 'complete', 'why', 'left', 'party', 'move', 'control', 'own', 'country', 'good', 'yes', 'there', 'less', 'government', 'thing', 'economy', 'lot', 'better', 'stay', 'matter', 'deciding', 'whether', 'remain', 'leaving', 'give', 'fuck', 'thought', 'far', 'ahead', 've', 'just', 'never', 'been', 'about', 'celebrating', 'democracy', 'alive', 'well', 'must', 'choose', 'between', 'open', 'sea', 'she', 'always', 'follow', 'shall', 'corrupt', 'destroy', 'through', 'riddance', 'jobs', 'first', 'let', 'go', 'commission', 'finally', 'moment', 'air', 'congratulations', 'men', 'proud', 'say', 'am', 'hope', 'see', 'much', 'from', 'land', 'churchill', 'voters', 'little', 'history', 'even', 'whole', 'ignorant', 'fools', 'many', 'lose', 'rest', 'care', 'because', 'paid', 'state', 'longer', 'money', 'up', 'most', 'important', 'things', 'kept', 'trying', 'quit', 'project', 'fear', 'remainer', 'lies', 'hate', 'propaganda', 'nationalism', 'twenty-nine', 'today', 'than', 'ever', 'negotiation', 'term', 'only', 'those', 'trade', 'negotiations', 'standards', 'll', 'creating', 'massive', 'euro', 'common', 'market', 'almost', 'oh', 'gets', 'option', 'peace', 'prosperity', 'away', 'too', 'really', 'showing', 'other', 'countries', 'out', 'antidemocratic', 'beyond', 'problem', 'cause', 'society', 'war', 'won', 'single', 'person', 'means', 'national', 'farmers', 'president', 'disastrous', 'would', 'industry', 'voting', 'point', 'family', 'shit', 'want', 'another', 'recession', 'middle', 'class', 'vote', 'ten', 'come', 'plan', 'again', 'imagine', 'based', 'very', 'reading', 'independent', 'once', 'listening', 'actually', 'them', 'respect', 'four', 'else', 'flag', 'pretty', 'benefits', 'totally', 'thinks', 'eighty', 'businesses', 'within', 'quite', 'story', 'directly', 'companies', 'thousands', 'small', 'firm', 'reality', 'same', 'larger', 'company', 'doesn', 'either', 'regulations', 'list', 'changed', 'isn', 'could', 'significant', 'popular', 'harder', 'possible', 'easier', 'pass', 'facts', 'profit', 'some', 'hard', 'advantage', 'few', 'racist', 'xenophobic', 'typical', 'cant', 'real', 'argument', 'support', 'instead', 'damn', 'making', 'example', 'club', 'thank', 'god', 'million', 'free', 'housing', 'prime', 'said', 'sort', 'pm', 'someone', 'decade', 'disgusting', 'human', 'shame', 'bbc', 'sky', 'voteleave', 'borisjohnson', 'level', 'push', 'into', 'time', 'completely', 'broken', 'he', 'gone', 'held', 'accountable', 'conservatives', 'everything', 'ensure', 'stopping', 'allowed', 'happen', 'trump', 'put', 'victory', 'western', 'taking', 'liberal', 'turned', 'wish', 'states', 'take', 'young', 'waiting', 'earth', 'kids', 'putting', 'brits', 'ppl', 'cost', 'lives', 'believe', 'call', 'yourself', 'such', 'waste', 'damaging', 'itself', 'madness', 'best', 'makes', 'feel', 'sad', 'angry', 'scared', 'embarrassed', 'terrified', 'times', 'ok', 'behind', 'twenty-eight', 'mr', 'made', 'utter', 'liar', 'law', 'got', 'straight', 'talking', 'became', 'period', 'dark', 'days', 'currently', 'kingdom', 'weaker', 'poorer', 'respected', 'pointless', 'done', 'mean', 'living', 'need', 'worse', 'before', 'shown', 'evidence', 'genuine', 'advantages', 'remaining', 'full', 'sense', 'whatsoever', 'brexitday', 'last', 'french', 'feels', 'wrong', 'promises', 'tory', 'north', 'south', 'black', 'policy', 'beginning', 'hit', 'opportunities', 'irish', 'germans', 'citizens', 'mp', 'comes', 'anything', 'dangerous', 'prefer', 'liberty', 'laws', 'borders', 'stop', 'sending', 'week', 'democratic', 'anyone', 'looks', 'referendum', 'theresa', 'did', 'bring', 'didn', 'here', 'fight', 'children', 'given', 'security', 'deserve', 'tell', 'cope', 'fed', 'doing', 'wanted', 'everywhere', 'sixteen', 'forty-eight', 'ready', 'these', 'criminals', 'told', 'taken', 'soon', 'deluded', 'second', 'constantly', 'until', 'knows', 'immigration', 'thursday', 'nodeal', 'deals', 'japan', 'cars', 'anyway', 'thanks', 'wo', 'off', 'clear', 'stopbrexit', 'damage', 'voteremain', 'beautiful', 'stronger', 'together', 'job', 'positive', 'personal', 'council', 'fifty', 'johnson', 'working', 'wto', 'where', 'total', 'since', 'transition', 'twenty', 'year', 'costs', 'con', 'austerity', 'wages', 'etc', 'expensive', 'govern', 'enough', 'stand', 'alone', 'seventy', 'billion', 'lol', 'known', 'norway', 'visa', 'travel', 'd', 'suggest', 'perhaps', 'awful', 'her', 'including', 'largest', 'easily', 'fine', 'england', 'switzerland', 'bureaucrats', 'able', 'something', 'case', 'scotland', 'opinion', 'both', 'sides', 'especially', 'votes', 'were', 'close', 'everyone', 'might', 'june', '23rd', 'independence', 'yeah', 'migrants', 'accept', 'result', 'thirty-nine', 'social', 'suicide', 'stage', 'governed', 'bunch', 'rich', 'tories', 'interests', 'everybody', 'u', 'prove', 'weak', 'man', 'old', 'built', 'twenty-seven', 'says', 'live', 'life', 'reason', 'europeans', 'proeu', 'signed', 'agreement', 'nobody', 'asked', 'created', 'soviet', 'six', 'separate', 'seven', 'create', 'provide', 'eight', 'turkey', 'join', 'around', 'several', 'supported', 'brought', 'closer', 'nato', 'ability', 'currency', 'goes', 'look', 'greece', 'spain', 'process', 'corporations', 'ones', 'camp', 'desperate', 'undemocratic', 'dear', 'leader', 'investment', 'strongerin', 'understand', 'stopped', 'extra', 'against', 'buy', 'grow', 'business', 'freedom', 'movement', 'sure', 'coming', 'citizen', 'thirteen', 'considering', 'mess', 'chaos', 'ago', 'pro', 'bureaucracy', 'points', 'video', 'difference', 'research', 'peoples', 'asking', 'eleven', 'weeks', 'luck', 'guys', 'turn', 'true', 'rights', 'shut', 'destroyed', 'selfish', 'seventeen', 'saw', 'scam', 'brain', 'morons', 'seventy-four', 'useless', 'near', 'parliament', 'foreign', 'outside', 'withdrawal', 'india', 'crisis', 'seventy-three', 'city', 'third', 'months', 'rubbish', 'wait', 'die', 'minds', 'clue', 'self', 'blame', 'admit', 'later', 'worst', 'decision', 'absolute', 'late', 'happened', 'unemployment', 'italy', 'sick', 'xenophobia', 'survive', 'remember', 'farage', 'love', '2nd', 'saying', 'scottish', 'nazi', 'january', 'america', 'rid', 'pounds', 'nothing', 'growth', 'speak', 'street', 'fifteen', 'him', 'his', 'supposed', 'home', 'millions', 'forty', 'exports', 'imports', 'hours', 'load', 'least', 'joined', 'area', 'treaties', 'forced', 'eussr', 'progress', 'yet', 'population', 'informed', 'leading', 'workers', 'hell', 'failed', 'listen', 'numbers', 'fair', 'run', 'youth', 'number', 'share', 'amongst', 'pushing', 'majority', 'criminal', 'trading', 'block', 'economies', 'took', 'canada', 'due', 'involved', 'clean', 'direction', 'ignored', 'wonder', 'crazy', 'biggest', 'position', 'stuff', 'benefit', 'giving', 'prepared', 'shows', 'low', 'brexiters', 'farce', 'rise', 'under', 'conservative', 'poverty', 'gb', 'step', 'nation', 'start', 'definitely', 'disaster', 'poor', 'outcome', 'further', 'house', 'rule', 'britannia', 'cheers', 'spoken', 'leavers', 'opportunity', 'correct', 'needs', 'save', 'worth', 'mass', 'final', 'border', 'controls', 'allow', 'resources', 'super', 'establishment', 'banks', 'quality', 'chance', 'tariffs', 'manufacturing', 'value', 'across', 'afford', 'legal', 'schools', 'running', 'funding', 'congrats', 'celebrate', 'sovereign', 'corbyn', 'boris', 'brilliant', 'new', 'seem', 'heart', 'crap', 'effort', 'decide', 'wales', 'northern', 'ireland', 'concerned', 'empty', 'break', 'hear', 'forward', 'needed', 'wake', 'brexiter', 'pay', 'twelve', 'act', 'large', 'fault', 'stability', 'order', 'nhs', 'education', 'matters', 'current', 'historic', 'stupidity', 'choice', 'britons', 'average', 'according', 'global', 'dumb', 'idea', 'falling', 'funny', 'show', 'glorious', 'doubt', 'successful', 'top', 'game', 'night', 'particular', 'road', 'usa', 'work', 'elect', 'ours', 'heads', 'information', 'front', 'become', 'cutting', 'spite', 'face', 'feeling', 'pride', 'affect', 'personally', 'east', 'families', 'spent', 'building', 'sooner', 'wing', 'minority', 'twenty-one', 'rather', 'deeply', 'watch', 'sadly', 'remainers', 'cliff', 'responsibility', 'decades', 'absolutely', 'gives', 'speech', 'ruled', 'unelected', 'prices', 'shortages', 'seems', 'wonderful', 'stupid', 'scaremongering', 'remoaner', 'liars', 'ridiculous', 'stories', 'fall', 'enjoy', 'politician', 'lying', 'sold', 'uneducated', 'electorate', 'generation', 'consider', 'gain', 'maybe', 'threat', 'agree', 'inside', 'decline', 'clearly', 'net', 'unless', 'helped', 'consequences', 'recent', 'campaign', 'hopefully', 'rejoin', 'sixty', 'ignorance', 'inevitable', 'themselves', 'pain', 'moving', 'tax', 'drop', 'price', 'paying', 'gdp', 'island', 'bloc', 'strong', 'starts', 'tiny', 'crash', 'therefore', 'nonsense', 'continue', 'charge', 'access', 'entire', 'elite', 'managed', 'hundreds', 'works', 'truly', 'per', 'affected', 'eighteen', 'mind', 'miss', 'half', 'line', 'nigel', 'fellow', 'arrogant', 'simply', 'bottom', 'health', 'piece', 'body', 'politics', 'felt', 'return', 'called', 'racists', 'queen', 'prevent', 'although', 'bloody', 'standing', 'read', 'ukip', 'rational', 'community', 'harm', 'citizenship', 'disgrace', 'already', 'waters', 'legislation', 'minister', 'dare', 'australia', 'main', 'experts', 'failure', 'economics', 'nearly', 'budget', 'brexiteers', 'ourselves', 'evil', 'empire', 'sorted', 'leaves', 'others', 'though', 'daily', 'macron', 'forces', 'thinking', 'fact', 'count', 'whatever', 'idiots', 'friday', 'valid', 'reasons', 'regain', 'sovereignty', 'fishing', 'thrive', 'economically', 'china', 'policies', 'import', 'export', 'cuts', 'place', 'smart', 'trust', 'goodness', 'probably', 'arrogance', 'following', 'enter', 'growing', 'brexshit', 'caused', 'bet', 'zero', 'surely', 'backstop', 'im', 'backing', 'deliver', 'delivered', 'relationship', 'agreements', 'amount', 'article', 'west', 'mps', 'lower', 'favour', 'freely', 'partners', 'starting', 'hatred', 'telling', 'convinced', 'westminster', 'risk', 'afraid', 'lots', 'despite', 'services', 'words', 'answer', 'antibrexit', 'agreed', 'wars', 'mention', 'found', 'friends', 'terms', 'german', 'vision', 'forget', 'onto', 'holding', 'certain', 'keeps', 'flags', 'generations', 'voices', 'plans', 'post', 'problems', 'whilst', 'past', 'century', 'none', 'apparently', 'glad', 'side', 'planet', 'stable', 'joke', 'lied', 'fucked', 'high', 'losing', 'different', 'media', '29th', 'fail', 'promised', 'welcome', 'ignore', 'leaders', 'heard', 'britains', 'seeing', 'perfect', 'simple', 'mentioned', 'nor', 'situation', 'putin', 'laughing', 'head', 'sorry', 'pound', 'elected', 'actions', 'impact', 'likely', 'losers', 'sign', 'crying', 'wont', 'win', 'looking', 'ninety', 'divided', 'bs', 'becomes', 'car', 'special', 'during', 'somehow', 'army', 'agenda', 'treaty', 'knew', 'anymore', 'scare', 'joining', 'stock', 'using', 'kind', 'passed', 'dictated', 'literally', 'wage', 'friend', 'fully', 'eastern', 'polls', 'older', 'wall', 'non', 'talks', 'allowing', 'commonwealth', 'interest', 'status', 'cares', 'myself', 'genuinely', 'suffer', 'lack', 'difficult', 'determination', 'american', 'revolution', 'ww2', 'finished', 'debt', 'wanting', 'among', 'amazing', 'labour', 'path', 'excellent', 'negative', 'values', 'beneficial', 'intelligent', 'train', 'places', 'abroad', 'tomorrow', 'regret', 'organisation', 'drag', 'success', 'protect', 'school', 'light', 'remains', 'nightmare', 'continues', 'try', 'ultimately', 'screwed', 'bureaucratic', 'destroying', 'globalists', 'passports', 'poland', 'facebook', 'build', 'realize', 'guess', 'loose', 'gave', 'ideas', 'screw', 'couple', 'happens', 'apply', 'cards', 'anger', 'gove', 'moved', 'uncertainty', 'brexiteer', 'oil', 'tv', 'exactly', 'interested', 'actual', 'eyes', 'decent', 'rhetoric', 'anybody', 'trusted', 'led', 'find', 'interesting', 'group', 'supporting', 'becoming', 'loss', 'surprised', 'fascist', 'idiot', 'plenty', 'individual', 'obvious', 'force', 'apart', 'racism', 'streets', 'changes', 'realise', 'aware', 'talk', 'solution', 'arguments', 'foreigners', 'greatest', 'seriously', 'throw', 'unity', 'goodbye', 'allies', 'climate', 'comments', 'biased', 'pathetic', 'brit', 'netherlands', 'expect', 'course', 'laugh', 'elites', 'skilled', 'blood', 'playing', 'table', 'lived', 'properly', 'bigger', 'equal', 'false', 'obviously', 'door', 'destruction', 'staying', 'voter', 'lord', 'bullies', 'stands', 'crime', 'spending', 'represent', 'younger', 'strongly', 'similar', 'issues', 'blaming', 'action', 'dying', 'effect', 'explain', 'sound', 'proper', 'ashamed', 'mostly', 'influence', 'strength', 'scale', 'neither', 'politically', 'leaver', 'remoaners', 'knowing', 'destiny', 'mafia', 'bank', 'express', 'incredibly', 'painful', 'sake', 'americans', 'globalism', 'keeping', 'indeed', 'disappointed', 'looked', 'culture', 'wishes', 'elections', 'anywhere', 'pure', 'reasonable', 'entirely', 'plus', 'pays', 'billions', 'development', 'white', 'debate', 'cameron', 'customs', 'negotiate', 'elsewhere', 'illegal', 'taxes', 'fix', 'upper', 'paper', 'view', 'cooperation', 'used', 'split', 'play', 'mainly', 'areas', 'easy', 'event', 'experiment', 'crumbling', 'migrant', 'shot', 'n', 'foot', 'identity', 'study', 'word', 'question', 'poll', 'supporters', 'results', 'prosperous', '11pm', 'tonight', 'faith', 'penny', 'walk', 'protection', 'imposed', 'voice', 'removed', 'local', 'kill', 'fish', 'lazy', 'socialist', 'sink', 'hoping', 'levels', 'morning', 'bye', 'unite', 'breaking', 'safety', 'stolen', 'demand', 'otherwise', 'lesson', 'industries', 'russia', 'enemy', 'continent', 'isolated', 'panic', 'hurt', 'modern', 'dictatorship', 'team', 'barnier', 'negotiating', 'deliberately', 'smaller', 'opposition', 'lets', 'heading', 'refugees', 'employment', 'issue', 'funded', 'educated', 'worried', 'soft', 'international', 'shooting', 'service', 'corruption', 'selling', 'honest', 'merkel', 'brings', 'worry', 'ordinary', 'woman', 'pushed', 'futures', 'eurocrats', 'dont', 'fool', 'women', 'pull', 'opposed', 'child', 'press', 'achieved', 'closing', 'except', 'offer', 'products', 'goods', 'effects', 'sane', 'sun', 'wealthy', 'cancel', 'collapse', 'tried', 'solve', 'cancelled', 'badly', 'tragedy', 'possibly', 'ties', 'silly', 'fantastic', 'migration', 'financially', 'owe', 'governments', 'capital', 'remove', 'above', 'horrible', 'nice', 'cancer', 'saved', 'university', 'learn', 'sweden', 'losses', 'sometimes', 'delay', 'kick', 'increase', 'send', 'chose', 'ruin', 'takes', 'freedoms', 'sensible', 'trouble', 'avoid', 'impossible', 'exist', 'civil', 'attempt', 'era', 'driven', 'bright', 'ill', 'flawed', 'ni', 'incompetent', 'approach', 'pensions', 'nasty', 'responsible', 'passport', 'powers', 'richer', 'normal', 'gon', 'na', 'doomed', 'pond', 'certainly', 'burn', 'puts', 'welfare', 'sit', 'fan', 'views', 'powerful', 'age', 'turning', 'nationalist', 'aim', 'safe', 'former', 'controlled', 'rotten', 'doesnt', 'particularly', 'compromise', 'ways', 'version', 'muslims', 'david', 'honestly', 'accountability', 'markets', 'russian', 'meant', 'tired', 'barriers', 'treason', 'potential', 'role', 'came', 'sinking', 'serious', 'f', 'bless', 'often', 'thick', 'fought', 'prosper', 'size', 'institutions', 'constant', 'ship', 'postbrexit', 'via', 'struggle', 'believed', 'unfortunately', 'fighting', 'fast', 'generally', 'hey', 'eec', 'eurozone', 'leadership', 'wow', 'seventy-five', 'stood', 'guy', 'claim', 'month', 'language', 'holiday', 'direct', 'calling', 'slowly', 'compared', 'cheap', 'federal', 'office', 'patriots', 'hilarious', 'wave', 'neighbours', 'unable', 'higher', 'frankly', 'desire', 'broke', 'goal', 'seat', 'e', 'extremely', 'officials', 'wealth', 'produce', 'surprise', 'tyranny', 'options', 'born', 'tears', 'shackles', 'attempts', 'un', 'dictate', 'probrexit', 'mep', 'behaviour', 'spend', 'crashing', 'closed']\n"
     ]
    }
   ],
   "source": [
    "print([el for el in test.keys() if test[el] >= 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-0976a054f4c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mstop_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "stop_words = []\n",
    "for x,y in test:\n",
    "    stop_words.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-07be5ff4bce8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstop_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stop_words' is not defined"
     ]
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = frozenset(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top_words\n",
    "len(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-40978219c500>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#stop_words = text.ENGLISH_STOP_WORDS.union(custom_stop_words)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENGLISH_STOP_WORDS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_words' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "#stop_words = text.ENGLISH_STOP_WORDS.union(custom_stop_words)\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(top_words)\n",
    "\n",
    "count = CountVectorizer()\n",
    "bag = count.fit_transform(list(data[\"Comment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = count.vocabulary_\n",
    "#sorted(d.items(), key=lambda x: x[1], reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-539-272ffbcda085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmyStr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"This this this is really really good.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmyDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Comment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class      5695\n",
       "Comment    5695\n",
       "dtype: int64"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data[data[\"Class\"] == '1']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Comment\"] = data[\"Comment\"].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Being a member of the European Union is a bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Brexit is bad. Immigrants make Britain great. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Britain is basically Pompeii if the Pompeii ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Britain's exit is a huge blow to the dream of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Death to the EU, Death to the EU!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13510</td>\n",
       "      <td>1</td>\n",
       "      <td>“we have made our choice”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13511</td>\n",
       "      <td>1</td>\n",
       "      <td>”Fake news! UK will prosper as soon as Bojo si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13513</td>\n",
       "      <td>1</td>\n",
       "      <td>🇬🇧 Hard Brexit all the way 🇬🇧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13514</td>\n",
       "      <td>0</td>\n",
       "      <td>😆 it's funny, when the brits sees the raise in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13515</td>\n",
       "      <td>0</td>\n",
       "      <td>🤣🤣 imagine that bulgarian and romanian passpor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class                                            Comment\n",
       "0         0  Being a member of the European Union is a bit ...\n",
       "1         0  Brexit is bad. Immigrants make Britain great. ...\n",
       "2         0  Britain is basically Pompeii if the Pompeii ha...\n",
       "3         1  Britain's exit is a huge blow to the dream of ...\n",
       "6         1                  Death to the EU, Death to the EU!\n",
       "...     ...                                                ...\n",
       "13510     1                          “we have made our choice”\n",
       "13511     1  ”Fake news! UK will prosper as soon as Bojo si...\n",
       "13513     1                      🇬🇧 Hard Brexit all the way 🇬🇧\n",
       "13514     0  😆 it's funny, when the brits sees the raise in...\n",
       "13515     0  🤣🤣 imagine that bulgarian and romanian passpor...\n",
       "\n",
       "[11004 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-38f2806a1bfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mREPLACE_BY_SPACE_RE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[/(){}\\[\\]\\|@,;]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mBAD_SYMBOLS_RE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^0-9a-z #+_]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mSTOPWORDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = text.replace('x', '')\n",
    "#    text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[\"Class\"]\n",
    "X = data[\"Comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xeval, Ytrain, Yeval = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['fuhrer', 'naive', 'passe'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8803, 500)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = TfidfVectorizer(max_features=500, strip_accents=\"unicode\", stop_words=stop_words, lowercase=True)\n",
    "#v = CountVectorizer(stop_words=stop_words, lowercase=True)\n",
    "X = v.fit_transform(X)\n",
    "Xtrain = v.transform(Xtrain)\n",
    "Xeval = v.transform(Xeval)\n",
    "Ytrain=Ytrain.astype('int')\n",
    "Yeval=Yeval.astype('int')\n",
    "Y=Y.astype('int')\n",
    "\n",
    "#print(vectorizer.get_feature_names())\n",
    "\n",
    "print(Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=0, shrinking=True, tol=1e-05,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(random_state=0, tol=1e-5)\n",
    "svc.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.756928668786915"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(svc.predict(Xeval), Yeval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(random_state=1, tol=1e-5, C=0.25)\n",
    "#svc.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7678328 , 0.72875965, 0.72648796, 0.73739209, 0.74409091])"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#accuracy_score(svc.predict(Xeval), Yeval)\n",
    "cross_val_score(svc, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[828, 230],\n",
       "       [218, 925]])"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(svc.predict(Xeval), Yeval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8997"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted(svc.coef_, reverse=True)\n",
    "len(svc.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7991821899136756"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(svc.predict(Xeval), Yeval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': array([1.000e-02, 1.001e+01, 2.001e+01, 3.001e+01, 4.001e+01, 5.001e+01,\n",
       "       6.001e+01, 7.001e+01, 8.001e+01, 9.001e+01])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C':np.arange(0.01,100,10)}\n",
    "svc = GridSearchCV(LinearSVC(),param_grid,cv=5,return_train_score=True)\n",
    "svc.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  \"stratified to prior in 0.24.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='warn')"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49977283053157656"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(dummy.predict(Xeval), Yeval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7233075874602454"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(gbc.predict(Xeval), Yeval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7905497501135847"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(nb.predict(Xeval), Yeval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=6000, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=6000)\n",
    "knn.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6106315311222171"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(knn.predict(Xeval), Yeval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7960018173557474"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(lr.predict(Xeval), Yeval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=100, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=100, n_estimators=500)\n",
    "rf.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'feature_names_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-505-d256cd5745d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'feature_names_'"
     ]
    }
   ],
   "source": [
    "rf.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7737392094502499"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(rf.predict(Xeval), Yeval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=80, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=80)\n",
    "tree.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(tree.feature_importances_, reverse=True)\n",
    "#tree.feature_names_\n",
    "#en(tree.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6855974557019536"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(tree.predict(Xeval), Yeval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(50, 50, 50), random_state=1)\n",
    "mlp.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.761017719218537"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(mlp.predict(Xeval), Yeval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=25, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=25, n_estimators=100)\n",
    "clf.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0 8325 8327 ... 7296 4573 1767]\n"
     ]
    }
   ],
   "source": [
    "importances = clf.feature_importances_\n",
    "indicies = np.argsort(importances)\n",
    "print(indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " 'nationality',\n",
       " 'nationals',\n",
       " 'nationwide',\n",
       " 'native',\n",
       " 'naturally',\n",
       " 'naughty',\n",
       " 'nauseous',\n",
       " 'naval',\n",
       " 'navel',\n",
       " 'navigate',\n",
       " 'navigation',\n",
       " 'naysayers',\n",
       " 'nazi',\n",
       " 'nazis',\n",
       " 'naïve',\n",
       " 'ne',\n",
       " 'neanderthals',\n",
       " 'nationalities',\n",
       " 'nearer',\n",
       " 'nationalists',\n",
       " 'nationalisation',\n",
       " 'nafta',\n",
       " 'nah',\n",
       " 'nailed',\n",
       " 'nails',\n",
       " 'naivety',\n",
       " 'naked',\n",
       " 'names',\n",
       " 'nancy',\n",
       " 'nannies',\n",
       " 'napoleon',\n",
       " 'narcisists',\n",
       " 'narcissists',\n",
       " 'narcotic',\n",
       " 'narratives',\n",
       " 'nastier',\n",
       " 'nasties',\n",
       " 'nastiest',\n",
       " 'nationalise',\n",
       " 'nears',\n",
       " 'necessary',\n",
       " 'neck',\n",
       " 'neighbourhood',\n",
       " 'neighbouring',\n",
       " 'neil',\n",
       " 'neill',\n",
       " 'nemesis',\n",
       " 'nemo',\n",
       " 'neo',\n",
       " 'neoliberal',\n",
       " 'neoliberalism',\n",
       " 'nephews',\n",
       " 'nepotism',\n",
       " 'nerve',\n",
       " 'nerves',\n",
       " 'nervewracking',\n",
       " 'ness',\n",
       " 'nest',\n",
       " 'netflix',\n",
       " 'neighbour',\n",
       " 'neighbors',\n",
       " 'neighbor',\n",
       " 'neigbours',\n",
       " 'necks',\n",
       " 'necrosis',\n",
       " 'nedxit',\n",
       " 'needing',\n",
       " 'needles',\n",
       " 'nefarious',\n",
       " 'negation',\n",
       " 'negatives',\n",
       " 'myths',\n",
       " 'negativity',\n",
       " 'neglect',\n",
       " 'negligible',\n",
       " 'negociate',\n",
       " 'negotations',\n",
       " 'negotiable',\n",
       " 'negotiated',\n",
       " 'negotiates',\n",
       " 'negotitions',\n",
       " 'negitivity',\n",
       " 'nets',\n",
       " 'mythic',\n",
       " 'myopic',\n",
       " 'mortal',\n",
       " 'mortals',\n",
       " 'mortgage',\n",
       " 'mortgages',\n",
       " 'morè',\n",
       " 'mosley',\n",
       " 'mostbrits',\n",
       " 'motions',\n",
       " 'motivated',\n",
       " 'motivates',\n",
       " 'motives',\n",
       " 'motors',\n",
       " 'moulded',\n",
       " 'mourn',\n",
       " 'mourning',\n",
       " 'mouse',\n",
       " 'moustache',\n",
       " 'morphing',\n",
       " 'mouth',\n",
       " 'morphed',\n",
       " 'moronic',\n",
       " 'monsieur',\n",
       " 'monsters',\n",
       " 'monstrosity',\n",
       " 'monstrous',\n",
       " 'monti',\n",
       " 'monty',\n",
       " 'monumentally',\n",
       " 'mooch',\n",
       " 'moochers',\n",
       " 'moodys',\n",
       " 'moore',\n",
       " 'mooring',\n",
       " 'morals',\n",
       " 'morass',\n",
       " 'morgan',\n",
       " 'morgherini',\n",
       " 'mornings',\n",
       " 'morph',\n",
       " 'mouthed',\n",
       " 'mouthiest',\n",
       " 'mouthpieces',\n",
       " 'mum',\n",
       " 'mumbo',\n",
       " 'mundane',\n",
       " 'muppet',\n",
       " 'murdering',\n",
       " 'murdoch',\n",
       " 'murky',\n",
       " 'muscle',\n",
       " 'muscles',\n",
       " 'museum',\n",
       " 'music',\n",
       " 'musicals',\n",
       " 'musings',\n",
       " 'muster',\n",
       " 'mutant',\n",
       " 'mutually',\n",
       " 'myopia',\n",
       " 'multitude',\n",
       " 'multiple',\n",
       " 'multinationals',\n",
       " 'multiculturalism',\n",
       " 'mouthy',\n",
       " 'movements',\n",
       " 'mowed',\n",
       " 'ms',\n",
       " 'msm',\n",
       " 'mt',\n",
       " 'mu5lim',\n",
       " 'muck',\n",
       " 'myriad',\n",
       " 'muddle',\n",
       " 'mudslum',\n",
       " 'mug',\n",
       " 'mugg',\n",
       " 'mugged',\n",
       " 'mugging',\n",
       " 'mugs',\n",
       " 'muh',\n",
       " 'multicultural',\n",
       " 'muddy',\n",
       " 'networks',\n",
       " 'neutered',\n",
       " 'nevercorbyn',\n",
       " 'nutters',\n",
       " 'nyc',\n",
       " 'nyse',\n",
       " 'nz',\n",
       " 'oak',\n",
       " 'oap',\n",
       " 'oaps',\n",
       " 'oasis',\n",
       " 'obcessed',\n",
       " 'obey',\n",
       " 'obfuscate',\n",
       " 'obfuscation',\n",
       " 'object',\n",
       " 'objected',\n",
       " 'objectively',\n",
       " 'objectives',\n",
       " 'objects',\n",
       " 'nutter',\n",
       " 'obliged',\n",
       " 'nutshell',\n",
       " 'nursing',\n",
       " 'nowdays',\n",
       " 'npc',\n",
       " 'npr',\n",
       " 'nt',\n",
       " 'nth',\n",
       " 'nts',\n",
       " 'nuance',\n",
       " 'nuanced',\n",
       " 'nuances',\n",
       " 'nuclear',\n",
       " 'nugent',\n",
       " 'nuisance',\n",
       " 'nuisances',\n",
       " 'numerous',\n",
       " 'numpties',\n",
       " 'numpty',\n",
       " 'nuremberg',\n",
       " 'nurture',\n",
       " 'obliterated',\n",
       " 'oblivion',\n",
       " 'oblivious',\n",
       " 'occur',\n",
       " 'occurred',\n",
       " 'ocean',\n",
       " 'oceanic',\n",
       " 'october',\n",
       " 'oddly',\n",
       " 'ode',\n",
       " 'oder',\n",
       " 'odious',\n",
       " 'oecd',\n",
       " 'ofcourse',\n",
       " 'offence',\n",
       " 'offending',\n",
       " 'offensive',\n",
       " 'offers',\n",
       " 'officers',\n",
       " 'offline',\n",
       " 'occupying',\n",
       " 'occupy',\n",
       " 'occupation',\n",
       " 'occasional',\n",
       " 'obliviously',\n",
       " 'obnoxious',\n",
       " 'obscene',\n",
       " 'obscure',\n",
       " 'observer',\n",
       " 'observers',\n",
       " 'obsessed',\n",
       " 'obsession',\n",
       " 'novice',\n",
       " 'obsessions',\n",
       " 'obstacle',\n",
       " 'obstacles',\n",
       " 'obstinately',\n",
       " 'obstructive',\n",
       " 'obtained',\n",
       " 'obtaining',\n",
       " 'obtains',\n",
       " 'occasion',\n",
       " 'obsessive',\n",
       " 'november',\n",
       " 'novels',\n",
       " 'novel',\n",
       " 'nights',\n",
       " 'nih',\n",
       " 'nilly',\n",
       " 'nincompoop',\n",
       " 'nip',\n",
       " 'nipple',\n",
       " 'nissans',\n",
       " 'nitra',\n",
       " 'nitrous',\n",
       " 'nitwits',\n",
       " 'niva',\n",
       " 'niverse',\n",
       " 'noah',\n",
       " 'nobel',\n",
       " 'noble',\n",
       " 'nobles',\n",
       " 'noboby',\n",
       " 'nightmares',\n",
       " 'nigerians',\n",
       " 'nigerian',\n",
       " 'nigels',\n",
       " 'newcastle',\n",
       " 'newcomers',\n",
       " 'newfound',\n",
       " 'newly',\n",
       " 'newspaper',\n",
       " 'newspapers',\n",
       " 'newsroom',\n",
       " 'newstopics',\n",
       " 'nobrexit',\n",
       " 'newzealand',\n",
       " 'ng',\n",
       " 'nhsto',\n",
       " 'niche',\n",
       " 'nick',\n",
       " 'nicola',\n",
       " 'nicolarse',\n",
       " 'nige',\n",
       " 'nigel_farage',\n",
       " 'nexit',\n",
       " 'monsato',\n",
       " 'nod',\n",
       " 'nodealbrexit',\n",
       " 'norton',\n",
       " 'norways',\n",
       " 'norwich',\n",
       " 'nostalgic',\n",
       " 'noted',\n",
       " 'notes',\n",
       " 'notfitforoffice',\n",
       " 'notice',\n",
       " 'noticeable',\n",
       " 'noticed',\n",
       " 'notification',\n",
       " 'noting',\n",
       " 'notinmyname',\n",
       " 'notion',\n",
       " 'notions',\n",
       " 'notmyprimeminister',\n",
       " 'notwithstanding',\n",
       " 'northwest',\n",
       " 'northumberland',\n",
       " 'northerners',\n",
       " 'northamptonshire',\n",
       " 'noeu',\n",
       " 'nogotiate',\n",
       " 'nonce',\n",
       " 'nonesense',\n",
       " 'nonexistent',\n",
       " 'nonsence',\n",
       " 'nonsensical',\n",
       " 'noo',\n",
       " 'nodeal',\n",
       " 'noon',\n",
       " 'nooooooo',\n",
       " 'noose',\n",
       " 'nordic',\n",
       " 'norhten',\n",
       " 'norm',\n",
       " 'normalisation',\n",
       " 'normalised',\n",
       " 'normally',\n",
       " 'noooo',\n",
       " 'offs',\n",
       " 'monoxide',\n",
       " 'monopolies',\n",
       " 'matched',\n",
       " 'material',\n",
       " 'materialized',\n",
       " 'materially',\n",
       " 'materials',\n",
       " 'matey',\n",
       " 'math',\n",
       " 'mathematical',\n",
       " 'mathematics',\n",
       " 'matthews',\n",
       " 'maturity',\n",
       " 'mauritania',\n",
       " 'maverick',\n",
       " 'max',\n",
       " 'maximises',\n",
       " 'mayo',\n",
       " 'mayyybe',\n",
       " 'match',\n",
       " 'mc',\n",
       " 'mastery',\n",
       " 'masterminds',\n",
       " 'martial',\n",
       " 'martyr',\n",
       " 'marx',\n",
       " 'marxism',\n",
       " 'marxist',\n",
       " 'mary',\n",
       " 'mascarade',\n",
       " 'mash',\n",
       " 'mask',\n",
       " 'masks',\n",
       " 'masochistic',\n",
       " 'masquerading',\n",
       " 'massacre',\n",
       " 'masse',\n",
       " 'masterbateus',\n",
       " 'masterclass',\n",
       " 'mastermind',\n",
       " 'masterplan',\n",
       " 'mcdonalds',\n",
       " 'mcdonnell',\n",
       " 'mcguiness',\n",
       " 'mediterranean',\n",
       " 'meds',\n",
       " 'meee',\n",
       " 'meekly',\n",
       " 'meet',\n",
       " 'meeting',\n",
       " 'meets',\n",
       " 'mega',\n",
       " 'megalomania',\n",
       " 'meghan',\n",
       " 'mein',\n",
       " 'melifluous',\n",
       " 'melt',\n",
       " 'melted',\n",
       " 'meme',\n",
       " 'memorable',\n",
       " 'memories',\n",
       " 'medieval',\n",
       " 'medicines',\n",
       " 'mediated',\n",
       " 'medal',\n",
       " 'mcguinness',\n",
       " 'mcmahon',\n",
       " 'meagre',\n",
       " 'meal',\n",
       " 'mealy',\n",
       " 'meaner',\n",
       " 'meanest',\n",
       " 'meaningful',\n",
       " 'marshalling',\n",
       " 'meaninglessness',\n",
       " 'meantime',\n",
       " 'measles',\n",
       " 'measurable',\n",
       " 'measure',\n",
       " 'measures',\n",
       " 'meat',\n",
       " 'mechanism',\n",
       " 'mechanisms',\n",
       " 'meanings',\n",
       " 'menace',\n",
       " 'mars',\n",
       " 'married',\n",
       " 'maggie',\n",
       " 'magical',\n",
       " 'magnificent',\n",
       " 'mainland',\n",
       " 'maintain',\n",
       " 'maintained',\n",
       " 'maintaining',\n",
       " 'mairead',\n",
       " 'maj',\n",
       " 'majesty',\n",
       " 'maker',\n",
       " 'makeshift',\n",
       " 'maket',\n",
       " 'mal',\n",
       " 'maladministration',\n",
       " 'malaysia',\n",
       " 'malcontents',\n",
       " 'madman',\n",
       " 'male',\n",
       " 'madhouse',\n",
       " 'madame',\n",
       " 'lurch',\n",
       " 'lurching',\n",
       " 'luther',\n",
       " 'luvvies',\n",
       " 'luxembourg',\n",
       " 'luxurious',\n",
       " 'ly',\n",
       " 'lyle',\n",
       " 'ma',\n",
       " 'maastricht',\n",
       " 'mac',\n",
       " 'macedonia',\n",
       " 'machinery',\n",
       " 'machines',\n",
       " 'macro',\n",
       " 'macron',\n",
       " 'madam',\n",
       " 'madeira',\n",
       " 'malevolent',\n",
       " 'malt',\n",
       " 'malta',\n",
       " 'manufacturers',\n",
       " 'manure',\n",
       " 'marched',\n",
       " 'marches',\n",
       " 'marching',\n",
       " 'marcus',\n",
       " 'margen',\n",
       " 'margin',\n",
       " 'marginalisation',\n",
       " 'mario',\n",
       " 'maritime',\n",
       " 'marked',\n",
       " 'marker',\n",
       " 'marks',\n",
       " 'marmite',\n",
       " 'marr',\n",
       " 'marriage',\n",
       " 'manufactured',\n",
       " 'manufacture',\n",
       " 'mans',\n",
       " 'manovering',\n",
       " 'maltese',\n",
       " 'mama',\n",
       " 'management',\n",
       " 'manager',\n",
       " 'managers',\n",
       " 'manages',\n",
       " 'manche',\n",
       " 'manchester',\n",
       " 'marrying',\n",
       " 'mandatory',\n",
       " 'maneuvered',\n",
       " 'manic',\n",
       " 'manifestly',\n",
       " 'manipulating',\n",
       " 'manipulation',\n",
       " 'manipulative',\n",
       " 'manipulators',\n",
       " 'manoeuvre',\n",
       " 'mandelson',\n",
       " 'mendacious',\n",
       " 'mendacity',\n",
       " 'mengele',\n",
       " 'mismanaged',\n",
       " 'mismanagement',\n",
       " 'misplaced',\n",
       " 'misreading',\n",
       " 'misstep',\n",
       " 'mistakes',\n",
       " 'mistreated',\n",
       " 'misty',\n",
       " 'misunderstand',\n",
       " 'misunderstood',\n",
       " 'mitigate',\n",
       " 'mix',\n",
       " 'mixing',\n",
       " 'mixture',\n",
       " 'mkay',\n",
       " 'mking',\n",
       " 'mmhh',\n",
       " 'misleads',\n",
       " 'mmm',\n",
       " 'misleading',\n",
       " 'misinformation',\n",
       " 'miracle',\n",
       " 'miraculous',\n",
       " 'mirage',\n",
       " 'mire',\n",
       " 'mired',\n",
       " 'mirroring',\n",
       " 'mis',\n",
       " 'misapprehension',\n",
       " 'misconduct',\n",
       " 'misdirection',\n",
       " 'misery',\n",
       " 'misfits',\n",
       " 'misfortune',\n",
       " 'misgivings',\n",
       " 'misguidance',\n",
       " 'misguide',\n",
       " 'misinform',\n",
       " 'misjudged',\n",
       " 'moaners',\n",
       " 'mobile',\n",
       " 'mobiles',\n",
       " 'momentus',\n",
       " 'mommy',\n",
       " 'moms',\n",
       " 'mon',\n",
       " 'monarch',\n",
       " 'monetary',\n",
       " 'monetize',\n",
       " 'monger',\n",
       " 'mongered',\n",
       " 'mongering',\n",
       " 'mongers',\n",
       " 'mongos',\n",
       " 'mongrel',\n",
       " 'monies',\n",
       " 'monitor',\n",
       " 'monolith',\n",
       " 'monolithic',\n",
       " 'momentum',\n",
       " 'moments',\n",
       " 'momentary',\n",
       " 'moloch',\n",
       " 'mobs',\n",
       " 'mobsters',\n",
       " 'mockery',\n",
       " 'modeled',\n",
       " 'modelling',\n",
       " 'models',\n",
       " 'moderately',\n",
       " 'moderator',\n",
       " 'minted',\n",
       " 'modernise',\n",
       " 'modicum',\n",
       " 'modified',\n",
       " 'mog',\n",
       " 'moggs',\n",
       " 'mojority',\n",
       " 'mold',\n",
       " 'moles',\n",
       " 'mollari',\n",
       " 'modernism',\n",
       " 'minsiter',\n",
       " 'mins',\n",
       " 'minorities',\n",
       " 'messieurs',\n",
       " 'metal',\n",
       " 'metastasized',\n",
       " 'meteor',\n",
       " 'method',\n",
       " 'methods',\n",
       " 'metric',\n",
       " 'metropolitan',\n",
       " 'mewling',\n",
       " 'mexicans',\n",
       " 'mf',\n",
       " 'mi',\n",
       " 'mi5',\n",
       " 'mi6',\n",
       " 'miasma',\n",
       " 'micers',\n",
       " 'micheal',\n",
       " 'messed',\n",
       " 'merthyr',\n",
       " 'merseyside',\n",
       " 'merry',\n",
       " 'mensa',\n",
       " 'mentality',\n",
       " 'mentatilty',\n",
       " 'mentioning',\n",
       " 'mentions',\n",
       " 'mep',\n",
       " 'meps',\n",
       " 'mercantilism',\n",
       " 'michel',\n",
       " 'mercedes',\n",
       " 'merchants',\n",
       " 'merciless',\n",
       " 'merger',\n",
       " 'merit',\n",
       " 'meritocracy',\n",
       " 'meritocratic',\n",
       " 'merits',\n",
       " 'merkler',\n",
       " 'mercer',\n",
       " 'monopoly',\n",
       " 'michigan',\n",
       " 'micromanagers',\n",
       " 'millenuim',\n",
       " 'miller',\n",
       " 'milli',\n",
       " 'millionaire',\n",
       " 'millionaires',\n",
       " 'mindedness',\n",
       " 'mindless',\n",
       " 'mindlessly',\n",
       " 'mindlessness',\n",
       " 'mindset',\n",
       " 'mines',\n",
       " 'minford',\n",
       " 'minimal',\n",
       " 'minimize',\n",
       " 'minimum',\n",
       " 'mining',\n",
       " 'minnesota',\n",
       " 'millennium',\n",
       " 'millennia',\n",
       " 'millenials',\n",
       " 'milkshake',\n",
       " 'micron',\n",
       " 'microsoft',\n",
       " 'mid',\n",
       " 'middleclass',\n",
       " 'middleman',\n",
       " 'middling',\n",
       " 'midget',\n",
       " 'midlands',\n",
       " 'micro',\n",
       " 'mighty',\n",
       " 'migrated',\n",
       " 'migrents',\n",
       " 'mike',\n",
       " 'mild',\n",
       " 'miles',\n",
       " 'miliband',\n",
       " 'militaristic',\n",
       " 'milking',\n",
       " 'migrate',\n",
       " 'offset',\n",
       " 'offshore',\n",
       " 'offshoring',\n",
       " 'ply',\n",
       " 'pms',\n",
       " 'pneumonia',\n",
       " 'pocket',\n",
       " 'pocketing',\n",
       " 'poets',\n",
       " 'pointed',\n",
       " 'pointing',\n",
       " 'poison',\n",
       " 'poisoned',\n",
       " 'poisoning',\n",
       " 'poisonous',\n",
       " 'poisons',\n",
       " 'poject',\n",
       " 'poke',\n",
       " 'poker',\n",
       " 'poket',\n",
       " 'plurality',\n",
       " 'polarised',\n",
       " 'pluralism',\n",
       " 'plundered',\n",
       " 'pleasant',\n",
       " 'pleasure',\n",
       " 'pleb',\n",
       " 'plebs',\n",
       " 'pledge',\n",
       " 'pledged',\n",
       " 'plonkers',\n",
       " 'plots',\n",
       " 'plotted',\n",
       " 'plotters',\n",
       " 'plotting',\n",
       " 'pls',\n",
       " 'plug',\n",
       " 'plugging',\n",
       " 'plumber',\n",
       " 'plummeted',\n",
       " 'plummets',\n",
       " 'plunge',\n",
       " 'policys',\n",
       " 'politburo',\n",
       " 'politeness',\n",
       " 'popular',\n",
       " 'popularity',\n",
       " 'populated',\n",
       " 'populistic',\n",
       " 'populists',\n",
       " 'populous',\n",
       " 'pork',\n",
       " 'portion',\n",
       " 'portioned',\n",
       " 'portray',\n",
       " 'portrayed',\n",
       " 'portuguese',\n",
       " 'posher',\n",
       " 'posing',\n",
       " 'posonous',\n",
       " 'possesses',\n",
       " 'possessive',\n",
       " 'populace',\n",
       " 'popcorn',\n",
       " 'pootin',\n",
       " 'pools',\n",
       " 'politian',\n",
       " 'politians',\n",
       " 'politic',\n",
       " 'politicans',\n",
       " 'politicize',\n",
       " 'politico',\n",
       " 'polled',\n",
       " 'pollies',\n",
       " 'pleas',\n",
       " 'pollutants',\n",
       " 'polluters',\n",
       " 'pollution',\n",
       " 'pompeii',\n",
       " 'pondering',\n",
       " 'pony',\n",
       " 'ponzi',\n",
       " 'pool',\n",
       " 'pooled',\n",
       " 'polluted',\n",
       " 'possibilities',\n",
       " 'plead',\n",
       " 'plc',\n",
       " 'phrase',\n",
       " 'phrases',\n",
       " 'phuck',\n",
       " 'pi',\n",
       " 'picked',\n",
       " 'pickle',\n",
       " 'pickles',\n",
       " 'pics',\n",
       " 'pictured',\n",
       " 'pictures',\n",
       " 'pie',\n",
       " 'piece',\n",
       " 'piecefully',\n",
       " 'pieces',\n",
       " 'piecewise',\n",
       " 'pierced',\n",
       " 'piers',\n",
       " 'photosynthesis',\n",
       " 'piffle',\n",
       " 'photos',\n",
       " 'philosophy',\n",
       " 'pests',\n",
       " 'petard',\n",
       " 'pete',\n",
       " 'peter',\n",
       " 'petting',\n",
       " 'peugeot',\n",
       " 'pharmaceutical',\n",
       " 'pharmaceuticals',\n",
       " 'phased',\n",
       " 'phases',\n",
       " 'phd',\n",
       " 'phenomena',\n",
       " 'phenomenal',\n",
       " 'philanderer',\n",
       " 'philippines',\n",
       " 'philips',\n",
       " 'philosophical',\n",
       " 'phones',\n",
       " 'piggy',\n",
       " 'pigshit',\n",
       " 'piled',\n",
       " 'plague',\n",
       " 'planes',\n",
       " 'planing',\n",
       " 'planks',\n",
       " 'planners',\n",
       " 'planning',\n",
       " 'planting',\n",
       " 'plastic',\n",
       " 'plate',\n",
       " 'platform',\n",
       " 'platitudes',\n",
       " 'plaxton',\n",
       " 'playboy',\n",
       " 'players',\n",
       " 'playgrounds',\n",
       " 'playmate',\n",
       " 'plays',\n",
       " 'placing',\n",
       " 'placid',\n",
       " 'placate',\n",
       " 'pizza',\n",
       " 'pilgramige',\n",
       " 'piling',\n",
       " 'pillaging',\n",
       " 'pillars',\n",
       " 'pineapple',\n",
       " 'pink',\n",
       " 'pint',\n",
       " 'pipe',\n",
       " 'plea',\n",
       " 'piper',\n",
       " 'pissing',\n",
       " 'pitchforks',\n",
       " 'pitching',\n",
       " 'pitfalls',\n",
       " 'pitiable',\n",
       " 'pitiful',\n",
       " 'pitying',\n",
       " 'pixxing',\n",
       " 'piracy',\n",
       " 'possition',\n",
       " 'possy',\n",
       " 'posted',\n",
       " 'principle',\n",
       " 'principled',\n",
       " 'print',\n",
       " 'printed',\n",
       " 'printing',\n",
       " 'prior',\n",
       " 'priorities',\n",
       " 'prioritise',\n",
       " 'prioritize',\n",
       " 'priority',\n",
       " 'prism',\n",
       " 'prisoner',\n",
       " 'prisoners',\n",
       " 'prisons',\n",
       " 'privatisation',\n",
       " 'privatise',\n",
       " 'privatised',\n",
       " 'principally',\n",
       " 'privatized',\n",
       " 'primitive',\n",
       " 'prides',\n",
       " 'pretends',\n",
       " 'pretense',\n",
       " 'pretext',\n",
       " 'prevailing',\n",
       " 'prevalent',\n",
       " 'prevaricating',\n",
       " 'prevarication',\n",
       " 'prevented',\n",
       " 'prevention',\n",
       " 'prevents',\n",
       " 'previous',\n",
       " 'previously',\n",
       " 'priapic',\n",
       " 'priced',\n",
       " 'priceless',\n",
       " 'prick',\n",
       " 'prideful',\n",
       " 'primate',\n",
       " 'privileged',\n",
       " 'prize',\n",
       " 'proactive',\n",
       " 'professor',\n",
       " 'professorship',\n",
       " 'profile',\n",
       " 'profit',\n",
       " 'profitable',\n",
       " 'profligacy',\n",
       " 'profligate',\n",
       " 'profound',\n",
       " 'profoundly',\n",
       " 'prog',\n",
       " 'program',\n",
       " 'programme',\n",
       " 'programmed',\n",
       " 'programmes',\n",
       " 'progresses',\n",
       " 'progressive',\n",
       " 'progressively',\n",
       " 'profession',\n",
       " 'prof',\n",
       " 'proeuropean',\n",
       " 'proeu',\n",
       " 'proaganda',\n",
       " 'prob',\n",
       " 'probable',\n",
       " 'probreakup',\n",
       " 'procedure',\n",
       " 'proceeded',\n",
       " 'proceeds',\n",
       " 'processes',\n",
       " 'pretence',\n",
       " 'proclaim',\n",
       " 'procrastination',\n",
       " 'prodigal',\n",
       " 'produced',\n",
       " 'producer',\n",
       " 'production',\n",
       " 'productivity',\n",
       " 'products',\n",
       " 'produktion',\n",
       " 'proclaiming',\n",
       " 'presumption',\n",
       " 'presumably',\n",
       " 'pressures',\n",
       " 'prageru',\n",
       " 'pragmatic',\n",
       " 'pragmatically',\n",
       " 'pragmatists',\n",
       " 'pram',\n",
       " 'prawn',\n",
       " 'prayed',\n",
       " 'prayer',\n",
       " 'prayers',\n",
       " 'praying',\n",
       " 'prayu',\n",
       " 'pre',\n",
       " 'preach',\n",
       " 'preaching',\n",
       " 'precautions',\n",
       " 'precede',\n",
       " 'precedent',\n",
       " 'practicing',\n",
       " 'practices',\n",
       " 'practiced',\n",
       " 'practice',\n",
       " 'poster',\n",
       " 'posterity',\n",
       " 'posters',\n",
       " 'postpone',\n",
       " 'postponing',\n",
       " 'posts',\n",
       " 'postwar',\n",
       " 'potatoes',\n",
       " 'precedents',\n",
       " 'potentials',\n",
       " 'pounce',\n",
       " 'pouring',\n",
       " 'powder',\n",
       " 'powell',\n",
       " 'powerhouse',\n",
       " 'powerless',\n",
       " 'powerlessness',\n",
       " 'poxy',\n",
       " 'pothole',\n",
       " 'pessina',\n",
       " 'preceding',\n",
       " 'predate',\n",
       " 'premiere',\n",
       " 'premium',\n",
       " 'preponderant',\n",
       " 'prescribe',\n",
       " 'presence',\n",
       " 'presentation',\n",
       " 'presenter',\n",
       " 'presenting',\n",
       " 'presently',\n",
       " 'presents',\n",
       " 'preservation',\n",
       " 'preserving',\n",
       " 'presided',\n",
       " 'presidency',\n",
       " 'presidential',\n",
       " 'presidents',\n",
       " 'pressing',\n",
       " 'premier',\n",
       " 'premature',\n",
       " ...]"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = v.get_feature_names()\n",
    "top_words = []\n",
    "\n",
    "for i in range(2000):\n",
    "    top_words.append(feature_names[indicies[i]])\n",
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4465 4453 1138 ...  966 4248  772]\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "m = LinearSVC()\n",
    "m.fit(Xtrain, Ytrain)\n",
    "\n",
    "# The estimated coefficients will all be around 1:\n",
    "#indicies = np.flip(np.argsort(np.abs(m.coef_)))[0]\n",
    "indicies = np.argsort(np.abs(m.coef_))[0]\n",
    "\n",
    "# Those values, however, will show that the second parameter\n",
    "# is more influential\n",
    "print(np.flip(np.argsort(np.std(Xtrain.todense()) * m.coef_))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = v.get_feature_names()\n",
    "top_words = []\n",
    "\n",
    "for i in range(4000):\n",
    "    top_words.append(feature_names[indicies[i]])\n",
    "#top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
